{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT NEO DISCORD.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaancolak979/Meteoroloji-Istasyonu-Web-Sitesi/blob/main/GPT_NEO_DISCORD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgfhFoA8WI9J"
      },
      "source": [
        "#GPT NEO based discord chatbot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Eq1gbpUWR1h"
      },
      "source": [
        "## Discord API\n",
        "You just need to insert your discord API and then run all the cells"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hSR9YYeVaPJ"
      },
      "source": [
        "discord_token = 'Nzk2NzExNzA4ODk0Mjk4MTU1.X_b5mQ.yEpDO31AIBKMMlzCMrWxh_KmYMg' #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2NFHj4tWY9z"
      },
      "source": [
        "##Module installation\n",
        "this will install all the necessary modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsJmPcofa006"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install discord.py\n",
        "!pip install nest_asyncio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ai3jougHXOfS"
      },
      "source": [
        "##Download and load GPT NEO model.\n",
        "It will take a little bit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyudeREf1uZQ"
      },
      "source": [
        "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
        "\n",
        "model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrBHO29EzInM"
      },
      "source": [
        "##Mode setup\n",
        "You can use this cell to select or create the desired mode\n",
        "To create a mode just follow this example:\n",
        "\n",
        "\n",
        "```python\n",
        "modes['mode_name'] = { 'prompt' : 'insert text that is put at the beginning of the input',\n",
        "                        'ai' : 'insert text before GPT messages',\n",
        "                        'human' : 'insert text befor human messages',\n",
        "                        'end' : 'a separator applied at the end of every message'\n",
        "                      }\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pjn1cPP75RAk"
      },
      "source": [
        "modes = dict()\n",
        "\n",
        "modes['chat'] = {'prompt' : 'This is a conversation with your friend\\n\\nYou: Hello.\\nFriend: Hi, how are you?\\nYou: Fine, and you?\\nFriend: I am fine, too.\\n',\n",
        "                           'human' : 'You: ',\n",
        "                           'ai' : 'Friend: ',\n",
        "                            'end' : '\\n'}\n",
        "\n",
        "modes['tldr'] = {'prompt' : 'Text Summarization\\n\\n',\n",
        "                  'human' : '',\n",
        "                  'ai' : '\\n\\nTL;DR: ',\n",
        "                  'end' : ''}\n",
        "\n",
        "modes['void'] = {'prompt' : '',\n",
        "                 'human' : '',\n",
        "                 'ai' : '',\n",
        "                 'end' : ''}\n",
        "\n",
        "mode = modes['chat']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FjWp2WizM2J"
      },
      "source": [
        "##Function to get GPT's answer from discord chat history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMY3qq5c5tmN"
      },
      "source": [
        "You can play with time_limit and max_length using the sliders. Time limit is very useful if you want fast replies by GPT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hspd_O3maydb"
      },
      "source": [
        "time_limit = 5 #@param {type:\"slider\", min:1, max:100, step:1}\n",
        "max_length = 2000 #@param {type:\"slider\", min:100, max:5000, step:1}\n",
        "\n",
        "def AI_answer(string):\n",
        "  in_string = mode['prompt'] + string\n",
        "  inputs = tokenizer.encode(in_string, return_tensors='pt')\n",
        "  inputs = inputs.cuda()\n",
        "  outputs = model.generate(inputs, max_length=max_length, do_sample=True, max_time=time_limit)\n",
        "  text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "  stripped_text = text[len(in_string):]\n",
        "\n",
        "  #preprocessing answer\n",
        "  if mode['human'] is not '' and mode['ai'] is not '':\n",
        "    stripped_text = stripped_text.split(mode['ai'])[1]\n",
        "    stripped_text = stripped_text.split(mode['human'])[0]\n",
        "  return stripped_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9nnXEh6zUXd"
      },
      "source": [
        "##Discord bot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKWSksHfd7NO"
      },
      "source": [
        "import discord\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "client = discord.Client()\n",
        "\n",
        "@client.event\n",
        "async def on_ready():\n",
        "    print('We have logged in as {0.user}'.format(client))\n",
        "\n",
        "@client.event\n",
        "async def on_message(message):\n",
        "    if message.author == client.user:\n",
        "        return\n",
        "\n",
        "    messages = await message.channel.history().flatten()\n",
        "    #create input string\n",
        "    in_string = ''\n",
        "    for message in reversed(messages):\n",
        "      \n",
        "      if message.author == client.user:\n",
        "        in_string += mode['ai']\n",
        "      else:\n",
        "        in_string += mode['human']\n",
        "      in_string += message.content + mode['end']\n",
        "\n",
        "    output = AI_answer(in_string)\n",
        "\n",
        "    await message.channel.send(output)\n",
        "\n",
        "client.run(discord_token)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}